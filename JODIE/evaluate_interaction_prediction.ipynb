{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_data import *\n",
    "from library_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE PARAMETERS\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.network = \"lastfm\"\n",
    "        self.train_proportion = 0.8\n",
    "        self.datapath = \"data/%s.csv\" % self.network\n",
    "        self.model = \"jodie\"\n",
    "        self.embedding_dim = 128\n",
    "        self.epochs = 49\n",
    "        self.state_change = False\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE PARAMETERS \n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--network', required=True, help='Network name')\n",
    "parser.add_argument('--model', default='jodie', help=\"Model name\")\n",
    "parser.add_argument('--gpu', default=\"0\", type=str, help='ID of the gpu to run on. If set to -1 (default), the GPU with most free memory will be chosen.')\n",
    "parser.add_argument('--epoch', default=50, type=int, help='Epoch id to load')\n",
    "parser.add_argument('--embedding_dim', default=128, type=int, help='Number of dimensions')\n",
    "parser.add_argument('--train_proportion', default=0.8, type=float, help='Proportion of training interactions')\n",
    "parser.add_argument('--state_change', default=True, type=bool, help='True if training with state change of users in addition to the next interaction prediction. False otherwise. By default, set to True. MUST BE THE SAME AS THE ONE USED IN TRAINING.') \n",
    "args = parser.parse_args()\n",
    "args.datapath = \"data/%s.csv\" % args.network\n",
    "if args.train_proportion > 0.8:\n",
    "    sys.exit('Training sequence proportion cannot be greater than 0.8.')\n",
    "if args.network == \"mooc\":\n",
    "    print(\"No interaction prediction for %s\" % args.network)\n",
    "    sys.exit(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = \"results/interaction_prediction_%s.txt\" % args.network\n",
    "if os.path.exists(output_fname):\n",
    "    f = open(output_fname, \"r\")\n",
    "    search_string = 'Test performance of epoch %d' % args.epochs\n",
    "    for l in f:\n",
    "        l = l.strip()\n",
    "        if search_string in l:\n",
    "            print(\"Output file already has results of epoch %d\" % args.epochs)\n",
    "            sys.exit(0)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tbatch_id</th>\n",
       "      <th>interactionids</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>state_label</th>\n",
       "      <th>user_timediffs</th>\n",
       "      <th>item_timediffs</th>\n",
       "      <th>previous_items</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137873</td>\n",
       "      <td>-0.305171</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23127.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.134138</td>\n",
       "      <td>-0.298293</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29342.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.133134</td>\n",
       "      <td>-0.296445</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44888.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.130624</td>\n",
       "      <td>-0.291821</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59063.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128335</td>\n",
       "      <td>-0.287606</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129306</th>\n",
       "      <td>12792</td>\n",
       "      <td>129307</td>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>137059703.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.091779</td>\n",
       "      <td>1.003544</td>\n",
       "      <td>866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129307</th>\n",
       "      <td>12793</td>\n",
       "      <td>129305</td>\n",
       "      <td>303</td>\n",
       "      <td>282</td>\n",
       "      <td>136942986.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137637</td>\n",
       "      <td>-0.304737</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129308</th>\n",
       "      <td>12793</td>\n",
       "      <td>129308</td>\n",
       "      <td>631</td>\n",
       "      <td>299</td>\n",
       "      <td>137069861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>-0.149005</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129309</th>\n",
       "      <td>12794</td>\n",
       "      <td>129309</td>\n",
       "      <td>631</td>\n",
       "      <td>674</td>\n",
       "      <td>137071402.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137624</td>\n",
       "      <td>1.124307</td>\n",
       "      <td>299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129310</th>\n",
       "      <td>12795</td>\n",
       "      <td>129310</td>\n",
       "      <td>631</td>\n",
       "      <td>704</td>\n",
       "      <td>137104632.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132506</td>\n",
       "      <td>1.399442</td>\n",
       "      <td>674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129311 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tbatch_id  interactionids  user_id  item_id    timestamp  state_label  \\\n",
       "0               1               0        0        0          0.0            0   \n",
       "1               1               2        1        2      23127.0            0   \n",
       "2               1               3        2        3      29342.0            0   \n",
       "3               1               4        3        4      44888.0            0   \n",
       "4               1               8        4        7      59063.0            0   \n",
       "...           ...             ...      ...      ...          ...          ...   \n",
       "129306      12792          129307      631      173  137059703.0            0   \n",
       "129307      12793          129305      303      282  136942986.0            0   \n",
       "129308      12793          129308      631      299  137069861.0            0   \n",
       "129309      12794          129309      631      674  137071402.0            0   \n",
       "129310      12795          129310      631      704  137104632.0            0   \n",
       "\n",
       "        user_timediffs  item_timediffs  previous_items    0  \n",
       "0            -0.137873       -0.305171            1000  0.0  \n",
       "1            -0.134138       -0.298293            1000  0.0  \n",
       "2            -0.133134       -0.296445            1000  0.0  \n",
       "3            -0.130624       -0.291821            1000  0.0  \n",
       "4            -0.128335       -0.287606            1000  0.0  \n",
       "...                ...             ...             ...  ...  \n",
       "129306       -0.091779        1.003544             866  0.0  \n",
       "129307       -0.137637       -0.304737             282  0.0  \n",
       "129308       -0.136232       -0.149005             173  0.0  \n",
       "129309       -0.137624        1.124307             299  0.0  \n",
       "129310       -0.132506        1.399442             674  0.0  \n",
       "\n",
       "[129311 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbatch_table = pd.read_csv(\"results/batches_lastfm.txt\", header=0)\n",
    "tbatch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequence_id = tbatch_table[\"user_id\"].to_numpy()\n",
    "user_timediffs_sequence = tbatch_table[\"user_timediffs\"].to_numpy()\n",
    "user_previous_itemid_sequence = tbatch_table[\"previous_items\"].to_numpy()\n",
    "item_sequence_id = tbatch_table[\"item_id\"].to_numpy()\n",
    "item_timediffs_sequence = tbatch_table[\"item_timediffs\"].to_numpy()\n",
    "timestamp_sequence = tbatch_table[\"timestamp\"].to_numpy()\n",
    "feature_sequence = tbatch_table[tbatch_table.columns[9:]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interactions = len(tbatch_table[\"interactionids\"])\n",
    "num_users = len(set(tbatch_table[\"user_id\"])) \n",
    "num_items = len(set(tbatch_table[\"item_id\"])) + 1 # one extra item for \"none-of-these\"\n",
    "num_features = len(tbatch_table.iloc[0]) - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET TRAIN, VALIDATION, AND TEST BOUNDARIES\n",
    "train_end_idx = validation_start_idx = int(num_interactions * args.train_proportion)\n",
    "test_start_idx = int(num_interactions * (args.train_proportion + 0.1))\n",
    "test_end_idx = int(num_interactions * (args.train_proportion + 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timespan = tbatch_table[\"timestamp\"].iloc[-1] - tbatch_table[\"timestamp\"][0]\n",
    "tbatch_timespan = timespan / 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initializing the JODIE model ***\n",
      "Initializing user and item embeddings\n",
      "Initializing user and item RNNs\n",
      "Initializing linear layers\n",
      "*** JODIE initialization complete ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE MODEL AND PARAMETERS\n",
    "model = JODIE(args, num_features, num_users, num_items).cuda()\n",
    "crossEntropyLoss = nn.CrossEntropyLoss()\n",
    "MSELoss = nn.MSELoss()\n",
    "binaryCrossEntropyLoss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE MODEL\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved embeddings and model: ./saved_models/lastfm/checkpoint.jodie.ep49.tp0.8.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE MODEL\n",
    "model, optimizer, user_embeddings_dystat, item_embeddings_dystat, user_embeddings_timeseries, item_embeddings_timeseries, train_end_idx_training = load_model(model, optimizer, args, args.epochs)\n",
    "if train_end_idx != train_end_idx_training:\n",
    "    sys.exit('Training proportion during training and testing are different. Aborting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THE USER AND ITEM EMBEDDINGS TO THEIR STATE AT THE END OF THE TRAINING PERIOD\n",
    "set_embeddings_training_end(user_embeddings_dystat, item_embeddings_dystat, user_embeddings_timeseries, item_embeddings_timeseries, user_sequence_id, item_sequence_id, train_end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE EMBEDDINGS: DYNAMIC AND STATIC\n",
    "item_embeddings = item_embeddings_dystat[:, :args.embedding_dim]\n",
    "item_embeddings = item_embeddings.clone()\n",
    "item_embeddings_static = item_embeddings_dystat[:, args.embedding_dim:]\n",
    "item_embeddings_static = item_embeddings_static.clone()\n",
    "\n",
    "user_embeddings = user_embeddings_dystat[:, :args.embedding_dim]\n",
    "user_embeddings = user_embeddings.clone()\n",
    "user_embeddings_static = user_embeddings_dystat[:, args.embedding_dim:]\n",
    "user_embeddings_static = user_embeddings_static.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE METRICS\n",
    "validation_ranks = []\n",
    "test_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Making interaction predictions by forward pass (no t-batching) ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92d159e497549a4b0f55abb6cefe998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25863.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-679e7dd6b31b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtbatch_start_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtbatch_timespan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtbatch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tbatch_start_time = None\n",
    "loss = 0\n",
    "# FORWARD PASS\n",
    "print(\"*** Making interaction predictions by forward pass (no t-batching) ***\")\n",
    "with trange(train_end_idx, test_end_idx) as progress_bar:\n",
    "    for j in progress_bar:\n",
    "        progress_bar.set_description('%dth interaction for validation and testing' % j)\n",
    "\n",
    "        # LOAD INTERACTION J\n",
    "        userid = user_sequence_id[j]\n",
    "        itemid = item_sequence_id[j]\n",
    "        feature = feature_sequence[j]\n",
    "        user_timediff = user_timediffs_sequence[j]\n",
    "        item_timediff = item_timediffs_sequence[j]\n",
    "        timestamp = timestamp_sequence[j]\n",
    "        if not tbatch_start_time:\n",
    "            tbatch_start_time = timestamp\n",
    "        itemid_previous = user_previous_itemid_sequence[j]\n",
    "\n",
    "        # LOAD USER AND ITEM EMBEDDING\n",
    "        user_embedding_input = user_embeddings[torch.cuda.LongTensor([userid])]\n",
    "        user_embedding_static_input = user_embeddings_static[torch.cuda.LongTensor([userid])]\n",
    "        item_embedding_input = item_embeddings[torch.cuda.LongTensor([itemid])]\n",
    "        item_embedding_static_input = item_embeddings_static[torch.cuda.LongTensor([itemid])]\n",
    "        feature_tensor = Variable(torch.Tensor(feature).cuda()).unsqueeze(0)\n",
    "        user_timediffs_tensor = Variable(torch.Tensor([user_timediff]).cuda()).unsqueeze(0)\n",
    "        item_timediffs_tensor = Variable(torch.Tensor([item_timediff]).cuda()).unsqueeze(0)\n",
    "        item_embedding_previous = item_embeddings[torch.cuda.LongTensor([itemid_previous])]\n",
    "\n",
    "        # PROJECT USER EMBEDDING\n",
    "        user_projected_embedding = model.forward(user_embedding_input, item_embedding_previous, timediffs=user_timediffs_tensor, features=feature_tensor, select='project')\n",
    "        user_item_embedding = torch.cat([user_projected_embedding, item_embedding_previous, item_embeddings_static[torch.cuda.LongTensor([itemid_previous])], user_embedding_static_input], dim=1)\n",
    "\n",
    "        # PREDICT ITEM EMBEDDING\n",
    "        predicted_item_embedding = model.predict_item_embedding(user_item_embedding)\n",
    "\n",
    "        # CALCULATE PREDICTION LOSS\n",
    "        loss += MSELoss(predicted_item_embedding, torch.cat([item_embedding_input, item_embedding_static_input], dim=1).detach())\n",
    "        \n",
    "        # CALCULATE DISTANCE OF PREDICTED ITEM EMBEDDING TO ALL ITEMS \n",
    "        euclidean_distances = nn.PairwiseDistance()(predicted_item_embedding.repeat(num_items, 1), torch.cat([item_embeddings, item_embeddings_static], dim=1)).squeeze(-1) \n",
    "        \n",
    "        # CALCULATE RANK OF THE TRUE ITEM AMONG ALL ITEMS\n",
    "        true_item_distance = euclidean_distances[itemid]\n",
    "        euclidean_distances_smaller = (euclidean_distances < true_item_distance).data.cpu().numpy()\n",
    "        true_item_rank = np.sum(euclidean_distances_smaller) + 1\n",
    "\n",
    "        if j < test_start_idx:\n",
    "            validation_ranks.append(true_item_rank)\n",
    "        else:\n",
    "            test_ranks.append(true_item_rank)\n",
    "\n",
    "        # UPDATE USER AND ITEM EMBEDDING\n",
    "        user_embedding_output = model.forward(user_embedding_input, item_embedding_input, timediffs=user_timediffs_tensor, features=feature_tensor, select='user_update') \n",
    "        item_embedding_output = model.forward(user_embedding_input, item_embedding_input, timediffs=item_timediffs_tensor, features=feature_tensor, select='item_update') \n",
    "\n",
    "        # SAVE EMBEDDINGS\n",
    "        item_embeddings[itemid,:] = item_embedding_output.squeeze(0) \n",
    "        user_embeddings[userid,:] = user_embedding_output.squeeze(0) \n",
    "        user_embeddings_timeseries[j, :] = user_embedding_output.squeeze(0)\n",
    "        item_embeddings_timeseries[j, :] = item_embedding_output.squeeze(0)\n",
    "\n",
    "        # CALCULATE LOSS TO MAINTAIN TEMPORAL SMOOTHNESS\n",
    "        loss += MSELoss(item_embedding_output, item_embedding_input.detach())\n",
    "        loss += MSELoss(user_embedding_output, user_embedding_input.detach())\n",
    "\n",
    "        # CALCULATE STATE CHANGE LOSS\n",
    "        if args.state_change:\n",
    "            loss += calculate_state_prediction_loss(model, [j], user_embeddings_timeseries, y_true, crossEntropyLoss) \n",
    "\n",
    "        # UPDATE THE MODEL IN REAL-TIME USING ERRORS MADE IN THE PAST PREDICTION\n",
    "        if timestamp - tbatch_start_time > tbatch_timespan:\n",
    "            tbatch_start_time = timestamp\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # RESET LOSS FOR NEXT T-BATCH\n",
    "            loss = 0\n",
    "            item_embeddings.detach_()\n",
    "            user_embeddings.detach_()\n",
    "            item_embeddings_timeseries.detach_() \n",
    "            user_embeddings_timeseries.detach_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE THE PERFORMANCE METRICS\n",
    "performance_dict = dict()\n",
    "ranks = validation_ranks\n",
    "mrr = np.mean([1.0 / r for r in ranks])\n",
    "rec10 = sum(np.array(ranks) <= 10)*1.0 / len(ranks)\n",
    "performance_dict['validation'] = [mrr, rec10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie40503/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/charlie40503/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d6fdf94e60aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrec10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mperformance_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "ranks = test_ranks\n",
    "mrr = np.mean([1.0 / r for r in ranks])\n",
    "rec10 = sum(np.array(ranks) <= 10)*1.0 / len(ranks)\n",
    "performance_dict['test'] = [mrr, rec10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-60a906703a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# PRINT AND SAVE THE PERFORMANCE METRICS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Mean Reciprocal Rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall@10'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_fname' is not defined"
     ]
    }
   ],
   "source": [
    "# PRINT AND SAVE THE PERFORMANCE METRICS\n",
    "fw = open(output_fname, \"a\")\n",
    "metrics = ['Mean Reciprocal Rank', 'Recall@10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n*** Validation performance of epoch %d ***' % args.epoch)\n",
    "fw.write('\\n\\n*** Validation performance of epoch %d ***\\n' % args.epoch)\n",
    "for i in xrange(len(metrics)):\n",
    "    print(metrics[i] + ': ' + str(performance_dict['validation'][i]))\n",
    "    fw.write(\"Validation: \" + metrics[i] + ': ' + str(performance_dict['validation'][i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n*** Test performance of epoch %d ***' % args.epoch)\n",
    "fw.write('\\n\\n*** Test performance of epoch %d ***\\n' % args.epoch)\n",
    "for i in xrange(len(metrics)):\n",
    "    print(metrics[i] + ': ' + str(performance_dict['test'][i]))\n",
    "    fw.write(\"Test: \" + metrics[i] + ': ' + str(performance_dict['test'][i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.flush()\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
